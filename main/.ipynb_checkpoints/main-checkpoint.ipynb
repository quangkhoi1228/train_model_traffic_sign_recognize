{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/train/0/\n",
      "../input/train/1/\n",
      "../input/train/2/\n",
      "../input/train/3/\n",
      "../input/train/4/\n",
      "../input/train/5/\n",
      "../input/train/6/\n",
      "../input/train/7/\n",
      "../input/train/8/\n",
      "../input/train/9/\n",
      "../input/train/10/\n",
      "../input/train/11/\n",
      "../input/train/12/\n",
      "../input/train/13/\n",
      "../input/train/14/\n",
      "../input/train/15/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15744 samples, validate on 3936 samples\n",
      "Epoch 1/5\n",
      "15744/15744 [==============================] - 42s 3ms/sample - loss: 1.3700 - accuracy: 0.5558 - val_loss: 0.2381 - val_accuracy: 0.9314\n",
      "Epoch 2/5\n",
      "15744/15744 [==============================] - 41s 3ms/sample - loss: 0.2968 - accuracy: 0.9052 - val_loss: 0.1091 - val_accuracy: 0.9677\n",
      "Epoch 3/5\n",
      " 4032/15744 [======>.......................] - ETA: 26s - loss: 0.1974 - accuracy: 0.9355"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "height = 30\n",
    "width = 30\n",
    "channels = 3\n",
    "classes = 16\n",
    "n_inputs = height * width*channels\n",
    "\n",
    "for i in range(classes) :\n",
    "    path = \"../input/train/{0}/\".format(i)\n",
    "    print(path)\n",
    "    Class=os.listdir(path)\n",
    "    for a in Class:\n",
    "        try:\n",
    "            image=cv2.imread(path+a)\n",
    "            image_from_array = Image.fromarray(image, 'RGB')\n",
    "            size_image = image_from_array.resize((height, width))\n",
    "            data.append(np.array(size_image))\n",
    "            labels.append(i)\n",
    "        except AttributeError:\n",
    "            print(\" \")\n",
    "            \n",
    "Cells=np.array(data)\n",
    "labels=np.array(labels)\n",
    "\n",
    "#Randomize the order of the input images\n",
    "s=np.arange(Cells.shape[0])\n",
    "np.random.seed(43)\n",
    "np.random.shuffle(s)\n",
    "Cells=Cells[s]\n",
    "labels=labels[s]\n",
    "\n",
    "#Spliting the images into train and validation sets\n",
    "(X_train,X_val)=Cells[(int)(0.2*len(labels)):],Cells[:(int)(0.2*len(labels))]\n",
    "X_train = X_train.astype('float32')/255 \n",
    "X_val = X_val.astype('float32')/255\n",
    "(y_train,y_val)=labels[(int)(0.2*len(labels)):],labels[:(int)(0.2*len(labels))]\n",
    "\n",
    "#Using one hote encoding for the train and validation labels\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, 43)\n",
    "y_val = to_categorical(y_val, 43)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "#using ten epochs for the training and saving the accuracy for each epoch\n",
    "epochs = 2\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=epochs,\n",
    "validation_data=(X_val, y_val))\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'], label='training loss')\n",
    "plt.plot(history.history['val_loss'], label='val loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "model.save('../model/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/train/0/\n",
      "../input/train/1/\n",
      "../input/train/2/\n",
      "../input/train/3/\n",
      "../input/train/4/\n",
      "../input/train/5/\n",
      "../input/train/6/\n",
      "../input/train/7/\n",
      "../input/train/8/\n",
      "../input/train/9/\n",
      "../input/train/10/\n",
      "../input/train/11/\n",
      "../input/train/12/\n",
      "../input/train/13/\n",
      "../input/train/14/\n",
      "../input/train/15/\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a6bb29dc689a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.compile(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
